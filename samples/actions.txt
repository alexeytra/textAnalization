model = Sequential()
model.add(layers.Dense(512, input_shape=(X_train.shape[1],)))
model.add(layers.Activation('relu'))
model.add(layers.Dropout(0.3))
model.add(layers.Dense(512))
model.add(layers.Activation('relu'))
model.add(layers.Dropout(0.3))
model.add(layers.Dense(3))
model.add(layers.Activation('softmax'))
model.summary()



#
# vocabulary = CountVectorizer()
# vocabulary.fit(sentences_train)
# X_train = vocabulary.transform(sentences_train)
# print(X_train)
#
# input_dim = X_train.shape[1]
# model = Sequential()
# model.add(layers.Dense(13, input_dim=input_dim, activation='relu'))
# model.add(layers.Dense(1, activation='sigmoid'))
# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# model.summary()
# history = model.fit(X_train, y_train, epochs=100, verbose=False, batch_size=5)
#
#
# vocabulary.fit(sentences_train)
# sentence = vocabulary.transform(voc.getCSVTest())
# print(model.predict_classes(sentence))


model.add(layers.Dense(200, input_shape=(X_train.shape[1],), activation='relu'))
model.add(layers.Dropout(0.3))
model.add(layers.Dense(100, activation='relu'))
model.add(layers.Dropout(0.3))
model.add(layers.Dense(num_samples, activation='softmax'))


df_list = []
table = pd.read_json('samples/train.json', encoding='utf-8', orient='index')
df_list.append(table)
df = pd.concat(df_list)
df['sentence'] = df['x'] + ' ' + df['R'] + ' ' + df['y']
sentences = df['sentence']
actions = df['action']

['Записать дефиницию', 'Построение правила', 'Записать ограничение',
       'Записать условие', 'Вычислить формулу']


{
  "": {
    "x": "",
    "R": "",
    "y": "",
    "action": ""
  }
}